\vspace{-1ex}
\section{Preliminaries}%%%%%%%%%JOURNAL%  and Definitions} 
\label{sec:krd_prel}
\vspace{-0.2ex}
We focus on discovering rules from RDF KBs. An RDF KB is
a database that represents information through RDF triples $\<s,p,o\>$, where a \emph{subject} ($s$) is connected to an \emph{object} ($o$) via a \emph{predicate} ($p$). Triples are often called \emph{facts}. For example, the fact that Scott Eastwood is the child of Clint Eastwood could be represented through the triple $\<Clint\_Eastwood,child,Scott\_Eastwood\>$. 
RDF KB triples respect three constraints:
\begin{inparaenum}[(i)]
	\item triple subjects are always \emph{entities}, i.e., concepts from the real world;
	\item triple objects can be either entities or \emph{literals}, i.e.,  primitive types such as numbers, dates, and strings;
	\item triple predicates specify real-world relationships between subjects and objects.
\end{inparaenum}
%%%%%%%TO BE REMOVED IF WE NEED MORE SPACE: %%%%%%%
%Entities in the KB model correspond to complex objects with properties and attributes in object oriented programming languages, while literals correspond to primitive types such as integers, chars and strings.
%%%%%%%%%%

Differently from relational databases, KBs usually do not have a schema that defines allowed instances,
% The set of predicates is unknown a-priori, 
and new predicates can be added by inserting triples. % having those predicates. 
%It is evident that 
This model allows great flexibility, but the likelihood of introducing errors is higher than traditional schema-guided databases.
While KBs can include \emph{T-Box} facts to define classes, domain/co-domain types for predicates, and relationships among classes
%While the T-Box can specify 
to check integrity, in most KBs -- including the ones used in our experiments -- such information is missing. % or not present at all. 
Hence our focus is on the \emph{A-Box} facts that describe instance data. 

\vspace{-1ex}
\subsection{Language} \label{sec:krd_language} 
\vspace{-0.2ex}
Our goal is to automatically discover 
%first-order logical formulas in KBs. More specifically, we target the discovery of 
\emph{Horn Rules} in KBs. A Horn Rule is a disjunction of \emph{atoms} with at most one unnegated atom. When written in the implication form, Horn Rules have one of the following formats:
%
\begin{equation*}
	A_1 \wedge A_2 \wedge \cdots \wedge A_n \Rightarrow B \qquad \qquad A_1 \wedge A_2 \wedge \cdots \wedge A_n \Rightarrow  \neg B
\end{equation*} %\neg B
%
where $A_1 \wedge A_2 \wedge \cdots \wedge A_n$ is the \emph{body} of the rule (a conjunction of atoms) and $B$ ($\neg B$) is the \emph{head} of the rule (a single atom). The head of the rule is either unnegated (left) or negated (right). We call the former \emph{definite clause} or \emph{positive rule}, as it generates new 
%positive 
facts (e.g., $r_1$ in Example~\ref{ex:krd_intro}). We call the latter \emph{goal clause} or \emph{negative rule} (e.g., $r_2$ in Example~\ref{ex:krd_intro}), as it identifies incorrect facts, similarly to denial constraints for relational data~\cite{chu2013discovering}. %In a KB, 
An atom is a predicate connecting two variables, two entities, or an entity and a variable. For simplicity, we represent an atom with the notation $\atom{rel}{a}{b}$, where \texttt{rel} is a predicate from the KB, and $a$, $b$ are either variables or entities. 
%NOT ESSENTIAL
%In the context of Horn Rules, all variables appearing in a rule are implicitly universally quantified.
Given a rule $r$, we define $r_{body}$ and $r_{head}$ as the body and the head of the rule, respectively. We define the variables in the head of the rule as the \emph{target variables}. 
%%%%%%%%%JOURNAL%For the sake of presentation, 
%We also write negative rules as definite clauses by rewriting a body atom %in its negated form 
%in the head. The result is a logically equivalent formula that emphasizes the generation of negative facts.
In Example~\ref{ex:krd_intro}, $r_1$ is a positive rule, where new positive facts are identified with target variables $a$ and $b$.
Rule $r_2$ instead is a negative rule to identify errors, where errors are related to target variables $a$ and $b$.
%we can rewrite it as a definite clause to derive false facts from the KB and obtain $r_2'$:
%\begin{equation*}
%	\atom{DOB}{a}{v_0} \wedge \atom{DOB}{b}{v_i} \wedge v_0 > v_i \Rightarrow  \atom{notChild}{a}{b}  
%\end{equation*} 
%
%\begin{example}\label{ex:ex2}
%	Rule $r_1$ in Example~\ref{ex:krd_intro} is a traditional positive rule, where new positive facts are identified with target variables $a$ and $b$.
%	% are the target variables.
%	Rule $r_2$ is a negative rule to identify errors.
%	
%%	 However, for other applications, we can rewrite it as a definite clause to derive false facts from the KB and obtain $r_2'$:
%%	
%%	\vspace{-4ex}
%%	{\small	
%%		\begin{equation*}
%%			\atom{DOB}{a}{v_0} \wedge \atom{DOB}{b}{v_i} \wedge v_0 > v_i
%%			\Rightarrow  \atom{notChild}{a}{b}  
%%		\end{equation*}
%%	}
%%	\vspace{-3.5ex}
%\end{example} 

As shown in $r_2$, we allow \emph{literal comparisons} in our rules. A literal comparison is a special atom $\atom{rel}{a}{b}$, where $\texttt{rel} \in \{<,\leq,\neq,>,\geq\}$, and $a$ and $b$ can only be assigned to literal values except if $\texttt{rel}$ is equal to $\neq$. In such a case $a$ and $b$ can be also assigned to entities. We will explain later on why this exception is important.

Given a KB $\kb$ and an atom $A=\atom{rel}{a}{b}$ where $a$ and $b$ are two entities, we say that $A$ \emph{holds} over $\kb$ iff $\<a,\texttt{rel},b\> \in \kb$.
Given %a KB $\kb$ and 
an atom $A=\atom{rel}{a}{b}$ with at least one variable, we say that $A$ can be \emph{instantiated} over $\kb$ if there exists at least one entity from $\kb$ for each variable in $A$ s.t. if we substitute all variables in $A$ with these entities, $A$ holds over $\kb$. Transitively, %given a body of a rule $r_{body}$, % and a KB $\kb$,
we say that $r_{body}$ can be instantiated over $\kb$ if every atom in $r_{body}$ can be instantiated. 

%Eventually, we introduce two language biases in order to avoid the explosion of the search space. 
%%%%%%%%%JOURNAL%%Following the biases introduced by other approaches for rule discovery in KBs~\cite{galarraga2015fast,Chen:2016}, 
%we adopt also two constraints on the variables in the rules.
% as a compromise between the expressiveness of the rules and the complexity of the discovery problem. 
As in other approaches~\cite{galarraga2015fast,Chen:2016}, we define a rule \emph{valid} iff it satisfies the following constraints.

\noindent {\bf Connectivity.} An atom $A_1$ can be reached by an atom $A_2$ iff $A_1$ and $A_2$ share at least one variable or one entity. 
%The connectivity constraint requires that 
%In a valid rule, 
Every atom must be \emph{transitively} reachable by any other atom in the rule.
%OR VIA A LITERAL COMPARISON??? %%%%%%%%%%%%%%%

\noindent {\bf Repetition.} Every variable in a rule must appear at least twice. Target variables already appear once in the head of the rule, but
%the repetition constraint limited to the body of a rule requires that 
each not target variable must be involved in a join or in a comparison.  
%%%%%%%%%JOURNAL%%%%%% (i.e., must appear at least twice).
%appear at least twice, while target variables at least once.

%%%%%%%%%JOURNAL%Language restrictions limit the algorithm output  to a subset of plausible rules. We will show in Section~\ref{sec:rules_gen} how these restrictions enable us to speed up the discovery process. % through a disk-based approach that leverages these limitations.

\vspace{-1ex}
\subsection{Rule Coverage}
\vspace{-0.2ex}
Given a pair of entities $(x,y)$ from a KB $\kb$ and a Horn Rule $r$, we say that $r_{body}$ \emph{covers} $(x,y)$ if
$(x,y) \models r_{body}$. In other words, given a rule $r : r_{body} \Rightarrow \atom{r}{a}{b}$, $r_{body}$ covers a pair of entities $(x,y) \in \kb$ iff we can substitute $a$ with $x$, $b$ with $y$, and the rest of the body can be instantiated over $\kb$. Given a set of pair of entities $E = \{(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\}$ and a rule $r$, we denote by $C_r(E)$ the \emph{coverage} of $r_{body}$ over $E$ as the set of elements in $E$ covered by $r_{body}$: $C_r(E)=\{(x,y) \in E | (x,y) \models r_{body}\}$.

Given the body $r_{body}$ of a rule $r$, we denote by $r^{*}_{body}$ the \emph{unbounded body} of $r$. The unbounded body of a rule is obtained by keeping only atoms that contain a target variable and substituting such atoms with new atoms where the target variable is paired with a new unique variable. As an example, given $r_{body} = \texttt{rel}_1\texttt{(}a,v_0\texttt{)} \wedge \texttt{rel}_2\texttt{(}v_0,b\texttt{)}$ where $a$ and $b$ are the target variables, $r^{*}_{body} = \texttt{rel}_1\texttt{(}a,v_i\texttt{)} \wedge \texttt{rel}_2\texttt{(}v_{ii},b\texttt{)}$.
While in $r_{body}$ the target variables are bounded to be connected by variable $v_0$, in $r^{*}_{body}$ %, the target variables 
they are unbounded.
Given a set of pair of entities $E = \{(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\}$ and a rule $r$, we denote by $U_r(E)$ the \emph{unbounded coverage} of $r^{*}_{body}$ over $E$ as the set of elements in $E$ covered by $r^{*}_{body}$: $U_r(E)=\{(x,y) \in E | (x,y) \models r^{*}_{body}\}$. Note that, given a set $E$, $C_r(E) \subseteq U_r(E)$. 
%In other words, the unbounded coverage of a rule over $E$ always contains all the elements of the coverage over $E$.

\begin{example}
	%Given rule $r_2$ of Example~\ref{ex:krd_intro} and a KB $\kb$, 
	We denote with $E$ the set of all possible pairs of entities in $\kb$. The coverage of $r_2$ of Example~\ref{ex:krd_intro} over $E$ $(C_r(E))$ is the set of all pairs of entities $(x,y) \in \kb$ s.t. both $x$ and $y$ have the \texttt{DOB} information and $x$ is born after $y$. The unbounded coverage of $r$ over $E$ $(U_r(E))$ is the set of all pairs of entities $(x,y)$ s.t. both $x$ and $y$ have the \texttt{DOB} information, no matter what the relation between the two birth dates is. 
\end{example} 

%\vspace{0.5ex}
The unbounded coverage is essential to distinguish between missing and inconsistent information: if for a pair of entities $(x,y)$ the \texttt{DOB} is missing for either $x$ or $y$ (or both), we cannot say whether $x$ was born before or after $y$. 
%therefore we cannot state whether the negative rule %of Example~\ref{ex:krd_intro} covers $(x,y)$ or not.
But if both $x$ and $y$ have the \texttt{DOB} and $x$ is born before $y$, we can affirm that $r_2$ does not cover $(x,y)$. Given that KBs are largely incomplete~\cite{min2013distant}, discriminating between missing and conflicting information is %of paramount
 essential.
%
We extend the definition of coverage and unbounded coverage to a set of rules $R=\{r_1,r_2,\cdots,r_n\}$ as the union of individual coverages:

\begin{equation*}
	C_R(E) = \bigcup \limits_{r \in R} C_r(E) \qquad U_R(E) = \bigcup \limits_{r \in R} U_r(E) 	\end{equation*}
\vspace{-3mm}


\section{Robust Rule Discovery} \label{sec:problem}
%Our problem tackles discovery %positive (negative)  rules for a 
We define the discovery for a {\em target predicate} given as input. 
To obtain all rules for a given KB, %As in other approaches~\cite{abedjan2014amending,galarraga2015fast}, 
we compute rules for every predicate in it. % and compute rules for each of them. % (see Section~
We characterize a predicate with two sets of pairs of entities.
%
The \emph{generation set} $G$ contains examples for the target predicate, 
while the \emph{validation set} $V$ contains counter examples for the target predicate.
Consider the discovery of positive rules for the {\tt child} predicate; $G$ contains examples of real pairs of parents and children and $V$ contains pairs of people who {\em are not} in a child relation. If we want to identify errors in the {\tt child} predicate (negative rules), the sets of examples are the same, but they switch role. To discover negative rules for {\tt child}, $G$ contains pairs of people not in a child relation and $V$ contains real pairs.
We explain in Section~\ref{sec:ex_generation} how to generate these two sets for a given predicate. 
%Note that our approach is not less generic than those mining rules for an entire KB: 
%it is true that we require a target predicate as input, however 
%\ref{sec:krd_comparative}).

We now formalize the \emph{exact discovery problem}. %\newline

\begin{definition}
	Given a KB $\kb$, two sets of pairs of entities $G$ and $V$ from $\kb$ with $G \cap V = \emptyset$, and all the valid Horn Rules $R$ for $\kb$, a solution for the \emph{exact discovery problem} is a subset $R'$ of $R$  s.t.:
	
	\vspace{-4mm}	
	\begin{equation*}
		\underset{R'}{\operatorname{argmin}}(size(R') | (C_{R'}(G) = G) \wedge (C_{R'}(V) \cap V = \emptyset))	\end{equation*}
	\end{definition}
	\vspace{-1ex}	

The exact solution is the minimal set of rules that covers all pairs in $G$ and none of the pairs in $V$. It minimizes the number of rules in the output ($size(R')$) to avoid overfitting rules covering only one pair, as such rules %like $R_{3}$ 
have very little impact when applied on the KB. In fact, given a pair of entities $(x,y)$, there is always an overfitting rule whose body covers only $(x,y)$ by assigning target variables to $x$ and $y$ as shown next. %$R_{3}$ does.


\begin{example}
	Consider the discovery of positive rules for the predicate {\tt couple} between two persons using as example the Obama family. A positive example is (Michelle, Barack) and a negative example is their daughters (Malia, Natasha). 
	Given three rules:
	
	\vspace{-1ex}	
	{\small	
		\begin{equation*}
		R_{1}:	\atom{livesIn}{a}{v_0} \wedge \atom{livesIn}{b}{v_0} \Rightarrow  \atom{couple}{a}{b}  
		\end{equation*}
			\vspace{-2ex}	
		\begin{equation*}
		R_{2}:	\atom{hasChild}{a}{v_i} \wedge \atom{hasChild}{b}{v_i} \Rightarrow  \atom{couple}{a}{b}  
		\end{equation*}
		\vspace{-1ex}	
		\begin{equation*}
			\begin{split}
			R_{3}:	\atom{hasChild}{Michelle}{Malia} \wedge  \atom{hasChild}{Barack}{Malia} \\ \Rightarrow \atom{couple}{Michelle}{Barack}
			\end{split}
		\end{equation*}
	}
	\vspace{-1ex}	
	
	\noindent
	Rule $R_{1}$ states that two persons are a couple if the live in the same place, while rule $R_{2}$ states that they are a couple if they have a child in common. Both rules cover the positive example, but $R_{1}$ covers also the negative one.
	% as also the daughters live in the same place. 
	$R_{2}$ is an exact solution. Rule $R_{3}$ explicitly mentions entity values in its head and body. It is also an exact solution, but overfits the given positive example. % as all of them live in the same place. 
\end{example} 

The example highlights that the exact discovery problem is not robust to %leads to poor rules because of the 
data quality problems in KBs. Even if a valid rule exists semantically, missing triples or errors for the examples in $G$ and $V$ can lead to faulty coverage, e.g., the rule misses a good example because a child relation is missing for M. Obama. %) or covers a negative one (). 
In the worst case, %the exact solution may collapse to a set of rules where 
every rule in the exact solution would cover only one example in $G$, % and none in $V$, 
i.e., a set of overfitting rules with very little effect on the KB.
%STEFANO CHECK CAREFULLY THE SENTENCEs ABOVE. WE report in some exp that we find zero rules, but rules with at least one tuple should be identified. We need to say somewhere the 1% threshold%%%%%%%%%%%%%%%%%%<<<<<<<<------------------------<<<<<<<<<-------
% difficult to use and understand.

\vspace{-1ex}	
\subsection{Weight Function} \label{sec:krd_weight_fun}
\vspace{-0.2ex}	
Given errors and missing information in both $G$ and $V$, we drop the requirement of exactly covering the sets with the rules. However, coverage is a strong indicator of quality: good rules should cover several examples in $G$, while covering several elements in $V$ is an indication of incorrect rules.
%, as we assume that errors are always a minority in the data. 
% we want to limit the coverage over $V$ to the minimum possible. 
We model these ideas as a \emph{weight} associated with every rule. % as follows.

%I REWRITE TO INCLUDE ALSO G IN THE SCORE, WHICH IS WHAT WE DO. THERE IS NO GUARANTEE THAT WE COVER ALL G %%%%%%%%%%%%<<<<<<<<<<<

\begin{definition}
\label{def:cost}
	Given a KB $\kb$, two sets of pair of entities $G$ and $V$ from $\kb$ with $G \cap V = \emptyset$, and a Horn Rule $r$, the {\em weight of $r$} is defined as follow:
	\begin{equation} \label{eq:weight_fun}
		w(r) = \alpha \cdot (1-\frac{\mid C_{r}(G)\mid}{\mid G \mid}) +\beta \cdot (\frac{\mid C_{r}(V) \mid}{\mid U_{r}(V)\mid})
	\end{equation}
	with $\alpha,\beta \in [0,1]$ and $\alpha + \beta = 1$, thus $w(r) \in [0,1]$. 
\end{definition}
%I SUGGEST TO KEEP ONLY ALPHA AND HAVE 1-ALPHA INSTEAD OF BETA%%%%%%%

The weight 
%is a value between $0$ and $1$ that 
captures the quality of a rule w.r.t. $G$ and $V$: the better the rule, the lower the weight -- a perfect rule covering all generation elements of $G$ and none of the validation elements in $V$ has a weight of $0$.
%this change must be correct. IF the one covering ONE CORRECT EXAMPLE in G and 0 in V is a perfect rule, we risk to have a solution with 0 cost but with tons of meaningless rules  %%%%%%%%%
%
The weight is made of two components normalized by parameters $\alpha$ and $\beta$.
The first component captures the coverage over the generation set $G$ -- the ratio between the coverage of $r$ over $G$ and $G$ itself.
	%If $r$ covers all elements in $G$, this component is $0$ because of the subtraction from $1$.
The second component quantifies the coverage of $r$ over $V$. The coverage over $V$ is divided by the unbounded coverage of $r$ over $V$, instead of the total elements in $V$, 
because some elements in $V$ might not have the predicates stated in $r_{body}$.
Intuitively, we restrict $V$ with unbounded coverage to validate on ``qualifying" examples that have the information tested by the rule's body.
	%because for those elements in $V$ that do not have predicates stated in $r_{body}$ we cannot be sure whether such elements are not covered by $r$. 
	%NOT CLEAR WHY WE CANNOT BE SURE :( %%%%%%%
%	Thus we divide the coverage over $V$ by the unbounded coverage of $r$ over $V$. 
	%Ideally this number is close to $0$.

Parameters $\alpha$ and $\beta$ give relevance to each component. A high $\beta$ steers the discovery towards rules with high precision by penalizing the ones that cover negative examples, % that identify few mistakes, or we would set 
while a high $\alpha$ champions the recall by favoring rules covering more generation examples. % as possible.
%remember to state this in exp

\begin{example}
	Consider again rule $r_2$ of Example~\ref{ex:krd_intro} 
	and two sets of pairs of entities $G$ and $V$ from a KB $\kb$. 
	%The two components of $w_r$ are computed as follow:
The first component of $w_r$ is computed as 1 minus the number of pairs $(x,y)$ in $G$ where
		$x$ is born after $y$ divided by the number of elements in $G$.
The second component is the ratio between number of pairs $(x,y)$ in $V$ where $x$ is born after $y$ and number of pairs $(x,y)$ in $V$ where the birth date for both $x$ and $y$ is known in $\kb$.
\end{example}

\begin{definition}
\label{def:totCost}
	Given a set of rules $R$, the {\em weight for $R$} is:
	\begin{equation*}
		w(R) = \alpha \cdot (1-\frac{\mid C_{R}(G)\mid}{\mid G \mid}) +\beta \cdot (\frac{\mid C_{R}(V) \mid}{\mid U_{R}(V)\mid})
	\end{equation*}
\end{definition}

Weights enable the modeling of the presence of errors in KBs. We will show in the experimental evaluation that several semantically correct rules have a significant coverage over $V$, which corresponds to potential errors in the KB. 
%The exact discovery problem implies the absence of errors in the input KB, however such an assumption is too strong for KBs built from external web sources~\cite{dong2014knowledge,shin2015incremental,suchanek2007yago} where inconsistencies are common~\cite{suchanek2009sofie}.

\vspace{-1ex}	
\subsection{Problem Definition} \label{sec:krd_prob_def}	
We can now state the approximate version of the problem.

\begin{definition}
	Given a KB $\kb$, two sets of pair of entities $G$ and $V$ from $\kb$ with $G \cap V = \emptyset$, all the valid Horn Rules $R$ for $\kb$, and a $w$ weight function for $R$, a solution for the \emph{approximate discovery problem} is a subset $R'$ of $R$  such that:
%
	$$\underset{R'}{\operatorname{argmin}}(w(R') | C_{R'}(G) = G)$$
\end{definition}
\vspace{-1ex}	

%Since we want to minimize the total weight of the output rules, 
The approximate version of the discovery problem aims to identify rules that cover all elements in $G$ and as few as possible elements in $V$. Since we do not want overfitting rules, we do not generate in $R$ rules having constants in both target variables.
%for each element $g \in G$ there always exists a rule that covers exactly only $g$ (single-instance rule), an admissible solution is guaranteed to exist. 
%We expect the output to be made of some rules that cover multiple examples in $G$, with the remaining examples in $G$ to be covered by single-instance rules. 
%In the best-case scenario a single rule covers all elements in $G$ and none of the elements in $V$.

We can map this problem to the {\em weighted set cover problem}, which is proven to be NP--complete~\cite{chvatal1979greedy}. The reduction follows immediately from the following mapping: 
the set of elements (universe) corresponds to the generation examples in $G$, the input sets are identify by the rules defined in $R$, the non-negative weight
function $w: r \rightarrow {\rm I\!R}$ is $w(r)$ in Definition~\ref{def:cost}, and the cost of $R$ is defined to be its total weight, according to Definition~\ref{def:totCost}. %TODO



%Section~\ref{sec:krd_greedy} will describe a greedy polynomial algorithm to find a good solution for the approximate discovery problem.